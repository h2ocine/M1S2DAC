{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from features import *\n",
    "\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from datasets import load_from_disk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from utils import preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 20360/20360 [00:00<00:00, 55554.24 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 2733/2733 [00:00<00:00, 41609.01 examples/s]\n",
      "Map: 100%|██████████| 6165/6165 [00:00<00:00, 56464.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "wikiqa_data = load_from_disk(\"wikiqa\")\n",
    "test_data_set = wikiqa_data[\"test\"]\n",
    "train_data_set = wikiqa_data[\"train\"]\n",
    "validation_data_set = wikiqa_data[\"validation\"]\n",
    "\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "    examples['question'] = [preprocess(q) for q in examples['question']]\n",
    "    examples['answer'] = [preprocess(a) for a in examples['answer']]\n",
    "    return examples\n",
    "\n",
    "train_data_set = train_data_set.map(preprocess_examples, batched=True)\n",
    "validation_data_set = validation_data_set.map(preprocess_examples, batched=True)\n",
    "test_data_set = test_data_set.map(preprocess_examples, batched=True)\n",
    "\n",
    "# Convertir en DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    'question': train_data_set['question'],\n",
    "    'answer': train_data_set['answer'],\n",
    "    'label': train_data_set['label']\n",
    "})\n",
    "\n",
    "validation_df = pd.DataFrame({\n",
    "    'question': validation_data_set['question'],\n",
    "    'answer': validation_data_set['answer'],\n",
    "    'label': validation_data_set['label']\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'question': test_data_set['question'],\n",
    "    'answer': test_data_set['answer'],\n",
    "    'label': test_data_set['label']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les questions sans réponse pertinente\n",
    "def filter_non_relevant(df):\n",
    "    relevant_questions = df[df['label'] == 1]['question'].unique()\n",
    "    return df[df['question'].isin(relevant_questions)]\n",
    "\n",
    "train_df = filter_non_relevant(train_df)\n",
    "validation_df = filter_non_relevant(validation_df)\n",
    "test_df = filter_non_relevant(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrouper les réponses et les labels pour chaque question\n",
    "def group_answers(df):\n",
    "    grouped = df.groupby('question').agg(list).reset_index()\n",
    "    return grouped\n",
    "\n",
    "train_grouped = group_answers(train_df)\n",
    "validation_grouped = group_answers(validation_df)\n",
    "test_grouped = group_answers(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def embed_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    word_vecs = [model[word] for word in words if word in model]\n",
    "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(model.vector_size)\n",
    "\n",
    "train_grouped['question_vec'] = train_grouped['question'].apply(embed_sentence)\n",
    "train_grouped['answer_vecs'] = train_grouped['answer'].apply(lambda answers: [embed_sentence(a) for a in answers])\n",
    "\n",
    "validation_grouped['question_vec'] = validation_grouped['question'].apply(embed_sentence)\n",
    "validation_grouped['answer_vecs'] = validation_grouped['answer'].apply(lambda answers: [embed_sentence(a) for a in answers])\n",
    "\n",
    "test_grouped['question_vec'] = test_grouped['question'].apply(embed_sentence)\n",
    "test_grouped['answer_vecs'] = test_grouped['answer'].apply(lambda answers: [embed_sentence(a) for a in answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe(df):\n",
    "    # Filtrer les lignes avec au moins 4 labels ou plus\n",
    "    filtered_df = df[df['label'].apply(lambda x: len(x) >= 4)]\n",
    "    return filtered_df\n",
    "\n",
    "train_grouped_filtered = filter_dataframe(train_grouped)\n",
    "\n",
    "validation_grouped_filtered = filter_and_limit_responses(validation_grouped)\n",
    "\n",
    "test_grouped_filtered = filter_and_limit_responses(test_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              question  \\\n",
      "0                            how a rocket engine works   \n",
      "1                how are aircraft radial engines built   \n",
      "2    how are cholera and typhus transmitted and pre...   \n",
      "3                         how are glacier caves formed   \n",
      "4    how are the of electrons in each shell determined   \n",
      "..                                                 ...   \n",
      "751  who wrote the song a little more country than ...   \n",
      "752                         who wrote the song cocaine   \n",
      "753                  who wrote the song feelin alright   \n",
      "754                    who wrote whats my name rihanna   \n",
      "755                          who wrote white christmas   \n",
      "\n",
      "                                                answer         label  \\\n",
      "0    [a rocket engine or simply rocket is a jet eng...  [1, 0, 0, 0]   \n",
      "1    [the radial engine is a reciprocating type int...  [1, 0, 0, 0]   \n",
      "2    [transmission occurs primarily by drinking wat...  [1, 0, 0, 0]   \n",
      "3    [a glacier cave is a cave formed within the ic...  [1, 0, 0, 0]   \n",
      "4    [each shell can contain only a fixed number of...  [1, 0, 0, 0]   \n",
      "..                                                 ...           ...   \n",
      "751  [a little more country than that is the title ...  [1, 0, 0, 0]   \n",
      "752  [cocaine is a song written and recorded by jj ...  [1, 0, 0, 0]   \n",
      "753  [feelin alright also known as feeling alright ...  [1, 0, 0, 0]   \n",
      "754  [the rb song was produced by the norwegian pro...  [1, 0, 0, 0]   \n",
      "755  [white christmas is an irving berlin song remi...  [1, 0, 0, 0]   \n",
      "\n",
      "                                          question_vec  \\\n",
      "0    [0.15490723, 0.11816406, -0.011108398, -0.0439...   \n",
      "1    [0.06514486, 0.12573242, 0.091430664, 0.088806...   \n",
      "2    [0.052001953, 0.056559246, 0.06315104, 0.05025...   \n",
      "3    [-0.008984375, 0.07998047, 0.045800783, 0.0598...   \n",
      "4    [0.08529663, 0.0027503967, 0.048797607, -0.006...   \n",
      "..                                                 ...   \n",
      "751  [0.063463, -0.010219998, 0.01894294, 0.0960286...   \n",
      "752  [0.12753907, -0.020837402, -0.005395508, 0.025...   \n",
      "753  [0.09956869, -0.004018148, 0.036051434, 0.0548...   \n",
      "754  [0.04353841, 0.010345459, 0.03680293, 0.114705...   \n",
      "755  [0.0077209473, 0.048171997, -0.05441284, 0.018...   \n",
      "\n",
      "                                           answer_vecs  \n",
      "0    [[0.08710734, 0.059940156, 0.022359213, 0.0036...  \n",
      "1    [[0.052048393, 0.07698959, 0.046286542, 0.0554...  \n",
      "2    [[-0.007805718, 0.05677626, 0.059021562, 0.109...  \n",
      "3    [[-0.09524536, 0.008273655, 0.020100912, 0.053...  \n",
      "4    [[0.09835568, -0.030860128, 0.06585508, 0.0438...  \n",
      "..                                                 ...  \n",
      "751  [[-0.03970602, -0.0020380435, 0.015831325, 0.1...  \n",
      "752  [[0.0038231744, 0.021272447, 0.064197116, 0.05...  \n",
      "753  [[0.05891087, -0.0075586983, 0.005429475, 0.07...  \n",
      "754  [[0.02389249, 0.042089287, 0.034859397, 0.0190...  \n",
      "755  [[0.04639376, 0.06319956, 0.021578275, 0.11081...  \n",
      "\n",
      "[756 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def filter_and_limit_responses(df):\n",
    "    # Fonction pour filtrer et limiter les réponses par question\n",
    "    new_rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answers = row['answer']\n",
    "        labels = row['label']\n",
    "        question_vec = row['question_vec']\n",
    "        answer_vecs = row['answer_vecs']\n",
    "\n",
    "        # Filtrer les réponses ayant des labels 1\n",
    "        filtered_answers = [ans for ans, lbl in zip(answers, labels) if lbl == 1]\n",
    "        filtered_labels = [lbl for lbl in labels if lbl == 1]\n",
    "        filtered_answer_vecs = [vec for vec, lbl in zip(answer_vecs, labels) if lbl == 1]\n",
    "\n",
    "        # Si moins de 4 réponses, ajouter des réponses ayant des labels 0\n",
    "        if len(filtered_answers) < 4:\n",
    "            for ans, lbl, vec in zip(answers, labels, answer_vecs):\n",
    "                if lbl == 0 and len(filtered_answers) < 4:\n",
    "                    filtered_answers.append(ans)\n",
    "                    filtered_labels.append(lbl)\n",
    "                    filtered_answer_vecs.append(vec)\n",
    "\n",
    "        # Si plus de 4 réponses, couper les réponses supplémentaires\n",
    "        filtered_answers = filtered_answers[:4]\n",
    "        filtered_labels = filtered_labels[:4]\n",
    "        filtered_answer_vecs = filtered_answer_vecs[:4]\n",
    "\n",
    "        # Ajouter la nouvelle ligne au dataframe\n",
    "        new_rows.append({\n",
    "            'question': question,\n",
    "            'answer': filtered_answers,\n",
    "            'label': filtered_labels,\n",
    "            'question_vec': question_vec,\n",
    "            'answer_vecs': filtered_answer_vecs\n",
    "        })\n",
    "\n",
    "    # Créer le nouveau dataframe\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# Remplacez `your_dataframe` par le nom de votre DataFrame\n",
    "test = filter_and_limit_responses(train_grouped_filtered)\n",
    "print(test)\n",
    "\n",
    "train_grouped_clean = filter_and_limit_responses(train_grouped_filtered)\n",
    "\n",
    "validation_grouped_clean = filter_and_limit_responses(validation_grouped_filtered)\n",
    "\n",
    "test_grouped_clean = filter_and_limit_responses(test_grouped_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "      <th>question_vec</th>\n",
       "      <th>answer_vecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how a rocket engine works</td>\n",
       "      <td>[a rocket engine or simply rocket is a jet eng...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.15490723, 0.11816406, -0.011108398, -0.0439...</td>\n",
       "      <td>[[0.08710734, 0.059940156, 0.022359213, 0.0036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how are aircraft radial engines built</td>\n",
       "      <td>[the radial engine is a reciprocating type int...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.06514486, 0.12573242, 0.091430664, 0.088806...</td>\n",
       "      <td>[[0.052048393, 0.07698959, 0.046286542, 0.0554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how are cholera and typhus transmitted and pre...</td>\n",
       "      <td>[transmission occurs primarily by drinking wat...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.052001953, 0.056559246, 0.06315104, 0.05025...</td>\n",
       "      <td>[[-0.007805718, 0.05677626, 0.059021562, 0.109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how are glacier caves formed</td>\n",
       "      <td>[a glacier cave is a cave formed within the ic...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[-0.008984375, 0.07998047, 0.045800783, 0.0598...</td>\n",
       "      <td>[[-0.09524536, 0.008273655, 0.020100912, 0.053...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how are the of electrons in each shell determined</td>\n",
       "      <td>[each shell can contain only a fixed number of...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.08529663, 0.0027503967, 0.048797607, -0.006...</td>\n",
       "      <td>[[0.09835568, -0.030860128, 0.06585508, 0.0438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>who wrote the song a little more country than ...</td>\n",
       "      <td>[a little more country than that is the title ...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.063463, -0.010219998, 0.01894294, 0.0960286...</td>\n",
       "      <td>[[-0.03970602, -0.0020380435, 0.015831325, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>who wrote the song cocaine</td>\n",
       "      <td>[cocaine is a song written and recorded by jj ...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.12753907, -0.020837402, -0.005395508, 0.025...</td>\n",
       "      <td>[[0.0038231744, 0.021272447, 0.064197116, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>who wrote the song feelin alright</td>\n",
       "      <td>[feelin alright also known as feeling alright ...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.09956869, -0.004018148, 0.036051434, 0.0548...</td>\n",
       "      <td>[[0.05891087, -0.0075586983, 0.005429475, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>who wrote whats my name rihanna</td>\n",
       "      <td>[the rb song was produced by the norwegian pro...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.04353841, 0.010345459, 0.03680293, 0.114705...</td>\n",
       "      <td>[[0.02389249, 0.042089287, 0.034859397, 0.0190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>who wrote white christmas</td>\n",
       "      <td>[white christmas is an irving berlin song remi...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>[0.0077209473, 0.048171997, -0.05441284, 0.018...</td>\n",
       "      <td>[[0.04639376, 0.06319956, 0.021578275, 0.11081...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                            how a rocket engine works   \n",
       "1                how are aircraft radial engines built   \n",
       "2    how are cholera and typhus transmitted and pre...   \n",
       "3                         how are glacier caves formed   \n",
       "4    how are the of electrons in each shell determined   \n",
       "..                                                 ...   \n",
       "751  who wrote the song a little more country than ...   \n",
       "752                         who wrote the song cocaine   \n",
       "753                  who wrote the song feelin alright   \n",
       "754                    who wrote whats my name rihanna   \n",
       "755                          who wrote white christmas   \n",
       "\n",
       "                                                answer         label  \\\n",
       "0    [a rocket engine or simply rocket is a jet eng...  [1, 0, 0, 0]   \n",
       "1    [the radial engine is a reciprocating type int...  [1, 0, 0, 0]   \n",
       "2    [transmission occurs primarily by drinking wat...  [1, 0, 0, 0]   \n",
       "3    [a glacier cave is a cave formed within the ic...  [1, 0, 0, 0]   \n",
       "4    [each shell can contain only a fixed number of...  [1, 0, 0, 0]   \n",
       "..                                                 ...           ...   \n",
       "751  [a little more country than that is the title ...  [1, 0, 0, 0]   \n",
       "752  [cocaine is a song written and recorded by jj ...  [1, 0, 0, 0]   \n",
       "753  [feelin alright also known as feeling alright ...  [1, 0, 0, 0]   \n",
       "754  [the rb song was produced by the norwegian pro...  [1, 0, 0, 0]   \n",
       "755  [white christmas is an irving berlin song remi...  [1, 0, 0, 0]   \n",
       "\n",
       "                                          question_vec  \\\n",
       "0    [0.15490723, 0.11816406, -0.011108398, -0.0439...   \n",
       "1    [0.06514486, 0.12573242, 0.091430664, 0.088806...   \n",
       "2    [0.052001953, 0.056559246, 0.06315104, 0.05025...   \n",
       "3    [-0.008984375, 0.07998047, 0.045800783, 0.0598...   \n",
       "4    [0.08529663, 0.0027503967, 0.048797607, -0.006...   \n",
       "..                                                 ...   \n",
       "751  [0.063463, -0.010219998, 0.01894294, 0.0960286...   \n",
       "752  [0.12753907, -0.020837402, -0.005395508, 0.025...   \n",
       "753  [0.09956869, -0.004018148, 0.036051434, 0.0548...   \n",
       "754  [0.04353841, 0.010345459, 0.03680293, 0.114705...   \n",
       "755  [0.0077209473, 0.048171997, -0.05441284, 0.018...   \n",
       "\n",
       "                                           answer_vecs  \n",
       "0    [[0.08710734, 0.059940156, 0.022359213, 0.0036...  \n",
       "1    [[0.052048393, 0.07698959, 0.046286542, 0.0554...  \n",
       "2    [[-0.007805718, 0.05677626, 0.059021562, 0.109...  \n",
       "3    [[-0.09524536, 0.008273655, 0.020100912, 0.053...  \n",
       "4    [[0.09835568, -0.030860128, 0.06585508, 0.0438...  \n",
       "..                                                 ...  \n",
       "751  [[-0.03970602, -0.0020380435, 0.015831325, 0.1...  \n",
       "752  [[0.0038231744, 0.021272447, 0.064197116, 0.05...  \n",
       "753  [[0.05891087, -0.0075586983, 0.005429475, 0.07...  \n",
       "754  [[0.02389249, 0.042089287, 0.034859397, 0.0190...  \n",
       "755  [[0.04639376, 0.06319956, 0.021578275, 0.11081...  \n",
       "\n",
       "[756 rows x 5 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grouped_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test de CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BY RANKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_train shape: (3024, 1, 300)\n",
      "a_train shape: (3024, 1, 300)\n",
      "y_train shape: (3024,)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    q_data = []\n",
    "    a_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        question_vec = np.array(row['question_vec'])\n",
    "        answer_vecs = np.array(row['answer_vecs'])\n",
    "        labels = row['label']\n",
    "\n",
    "        num_answers = len(answer_vecs)\n",
    "        q_data.extend([question_vec] * num_answers)\n",
    "        a_data.extend(answer_vecs)\n",
    "        y_data.extend(labels)\n",
    "\n",
    "    q_data = np.expand_dims(np.array(q_data), axis=1)  # Ajouter une dimension pour l'axe de séquence\n",
    "    a_data = np.expand_dims(np.array(a_data), axis=1)  # Ajouter une dimension pour l'axe de séquence\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    return q_data, a_data, y_data\n",
    "\n",
    "q_train, a_train, y_train = prepare_data(train_grouped_clean)\n",
    "\n",
    "# Afficher les formes pour vérifier\n",
    "print(f'q_train shape: {q_train.shape}')\n",
    "print(f'a_train shape: {a_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_shape: (1, 300)\n",
      "answer_shape: (1, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_173\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_173\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_211     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_212     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │ input_layer_211[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_layer_212[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │ conv1d_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ conv1d_109[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,100</span> │ conv1d_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ conv1d_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_107     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_213     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_108     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_213[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">54,016</span> │ concatenate_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_87          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_173[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_211     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_212     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_109 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m30,100\u001b[0m │ input_layer_211[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_layer_212[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_110 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m30,100\u001b[0m │ conv1d_109[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ conv1d_109[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_111 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m50,100\u001b[0m │ conv1d_110[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ conv1d_110[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_111[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_111[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_107     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_213     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_108     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m210\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_107[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_213[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_173 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m54,016\u001b[0m │ concatenate_108[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_87          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_173[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_174 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dropout_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,573</span> (642.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m164,573\u001b[0m (642.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,573</span> (642.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,573\u001b[0m (642.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def create_bi_cnn_model(question_shape, answer_shape, num_features=None):\n",
    "    # Define question input\n",
    "    question_input = layers.Input(shape=question_shape)\n",
    "    answer_input = layers.Input(shape=answer_shape)\n",
    "    \n",
    "    # First convolutional layer with kernel size of 1\n",
    "    conv1 = layers.Conv1D(100, kernel_size=1, activation='tanh')\n",
    "    \n",
    "    # Second convolutional layer with kernel size of 3\n",
    "    conv2 = layers.Conv1D(100, kernel_size=3, activation='tanh', padding='same')\n",
    "    \n",
    "    # Third convolutional layer with kernel size of 5\n",
    "    conv3 = layers.Conv1D(100, kernel_size=5, activation='tanh', padding='same')\n",
    "    \n",
    "    # Process question and answer vectors through multiple convolutional layers\n",
    "    q_conv1 = conv1(question_input)\n",
    "    q_conv2 = conv2(q_conv1)\n",
    "    q_conv3 = conv3(q_conv2)\n",
    "    \n",
    "    a_conv1 = conv1(answer_input)\n",
    "    a_conv2 = conv2(a_conv1)\n",
    "    a_conv3 = conv3(a_conv2)\n",
    "    \n",
    "    # Max pooling\n",
    "    q_pool = layers.GlobalMaxPooling1D()(q_conv3)\n",
    "    a_pool = layers.GlobalMaxPooling1D()(a_conv3)\n",
    "    \n",
    "    # Concatenate pooled outputs\n",
    "    combined = layers.Concatenate()([q_pool, a_pool])\n",
    "    \n",
    "    if num_features is not None:\n",
    "        # Add the additional features if available\n",
    "        external_features = layers.Input(shape=(num_features,))\n",
    "        combined_with_features = layers.Concatenate()([combined, external_features])\n",
    "        \n",
    "        # Fully connected layer\n",
    "        dense = layers.Dense(256, activation='relu')(combined_with_features)\n",
    "        dropout = layers.Dropout(0.5)(dense)\n",
    "        output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = models.Model(inputs=[question_input, answer_input, external_features], outputs=output)\n",
    "    else:\n",
    "        # Fully connected layer\n",
    "        dense = layers.Dense(256, activation='relu')(combined)\n",
    "        dropout = layers.Dropout(0.5)(dense)\n",
    "        output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = models.Model(inputs=[question_input, answer_input], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Assuming q_train and a_train are your training data\n",
    "question_shape = (q_train.shape[1], q_train.shape[2])  # (sequence_length, embedding_dimension)\n",
    "answer_shape = (a_train.shape[1], a_train.shape[2])    # (sequence_length, embedding_dimension)\n",
    "\n",
    "print(f'question_shape: {question_shape}')\n",
    "print(f'answer_shape: {answer_shape}')\n",
    "\n",
    "model = create_bi_cnn_model(question_shape, answer_shape, num_features=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4175 - loss: 0.7004 - val_accuracy: 0.6568 - val_loss: 0.6582\n",
      "Epoch 2/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5993 - loss: 0.6683 - val_accuracy: 0.6667 - val_loss: 0.5861\n",
      "Epoch 3/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5916 - loss: 0.6607 - val_accuracy: 0.5776 - val_loss: 0.6405\n",
      "Epoch 4/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6010 - loss: 0.6285 - val_accuracy: 0.6337 - val_loss: 0.5953\n",
      "Epoch 5/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6208 - loss: 0.6241 - val_accuracy: 0.6568 - val_loss: 0.5961\n",
      "Epoch 6/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 0.6124 - val_accuracy: 0.5644 - val_loss: 0.6624\n",
      "Epoch 7/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6482 - loss: 0.5783 - val_accuracy: 0.6007 - val_loss: 0.6735\n",
      "Epoch 8/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6745 - loss: 0.5563 - val_accuracy: 0.6205 - val_loss: 0.6217\n",
      "Epoch 9/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6774 - loss: 0.5371 - val_accuracy: 0.6106 - val_loss: 0.6760\n",
      "Epoch 10/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7043 - loss: 0.5169 - val_accuracy: 0.6238 - val_loss: 0.7007\n",
      "Epoch 11/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6892 - loss: 0.5180 - val_accuracy: 0.6172 - val_loss: 0.7480\n",
      "Epoch 12/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7453 - loss: 0.4784 - val_accuracy: 0.6337 - val_loss: 0.7842\n",
      "Epoch 13/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7557 - loss: 0.4634 - val_accuracy: 0.6337 - val_loss: 0.7923\n",
      "Epoch 14/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7404 - loss: 0.4570 - val_accuracy: 0.6535 - val_loss: 0.9635\n",
      "Epoch 15/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7588 - loss: 0.4483 - val_accuracy: 0.6007 - val_loss: 0.9348\n",
      "Epoch 16/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7568 - loss: 0.4291 - val_accuracy: 0.6469 - val_loss: 0.9200\n",
      "Epoch 17/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7922 - loss: 0.4107 - val_accuracy: 0.6238 - val_loss: 0.9473\n",
      "Epoch 18/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8028 - loss: 0.3930 - val_accuracy: 0.6271 - val_loss: 1.0408\n",
      "Epoch 19/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.3871 - val_accuracy: 0.6271 - val_loss: 0.9592\n",
      "Epoch 20/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8088 - loss: 0.3812 - val_accuracy: 0.5809 - val_loss: 1.1204\n",
      "Epoch 21/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8221 - loss: 0.3450 - val_accuracy: 0.6337 - val_loss: 1.1357\n",
      "Epoch 22/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8322 - loss: 0.3376 - val_accuracy: 0.5677 - val_loss: 1.1850\n",
      "Epoch 23/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8283 - loss: 0.3400 - val_accuracy: 0.6271 - val_loss: 1.2577\n",
      "Epoch 24/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8007 - loss: 0.4229 - val_accuracy: 0.6040 - val_loss: 1.1635\n",
      "Epoch 25/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6926 - loss: 0.5287 - val_accuracy: 0.6040 - val_loss: 0.9224\n",
      "Epoch 26/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7595 - loss: 0.4569 - val_accuracy: 0.5380 - val_loss: 0.9699\n",
      "Epoch 27/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7621 - loss: 0.4257 - val_accuracy: 0.6139 - val_loss: 1.1705\n",
      "Epoch 28/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.3742 - val_accuracy: 0.6172 - val_loss: 1.2918\n",
      "Epoch 29/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8259 - loss: 0.3326 - val_accuracy: 0.6535 - val_loss: 1.3303\n",
      "Epoch 30/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8662 - loss: 0.2904 - val_accuracy: 0.5908 - val_loss: 1.3023\n",
      "Epoch 31/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8472 - loss: 0.2905 - val_accuracy: 0.6667 - val_loss: 1.4154\n",
      "Epoch 32/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8629 - loss: 0.2890 - val_accuracy: 0.6403 - val_loss: 1.5487\n",
      "Epoch 33/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8607 - loss: 0.2826 - val_accuracy: 0.6271 - val_loss: 1.4493\n",
      "Epoch 34/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2380 - val_accuracy: 0.6403 - val_loss: 1.4997\n",
      "Epoch 35/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8054 - loss: 0.3893 - val_accuracy: 0.6502 - val_loss: 1.4417\n",
      "Epoch 36/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8602 - loss: 0.2893 - val_accuracy: 0.6403 - val_loss: 1.5346\n",
      "Epoch 37/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8908 - loss: 0.2481 - val_accuracy: 0.6469 - val_loss: 1.7378\n",
      "Epoch 38/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8824 - loss: 0.2441 - val_accuracy: 0.6271 - val_loss: 1.7798\n",
      "Epoch 39/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8919 - loss: 0.2492 - val_accuracy: 0.6106 - val_loss: 1.7407\n",
      "Epoch 40/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.2145 - val_accuracy: 0.6799 - val_loss: 2.1366\n",
      "Epoch 41/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8790 - loss: 0.2957 - val_accuracy: 0.6601 - val_loss: 1.9849\n",
      "Epoch 42/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8936 - loss: 0.2498 - val_accuracy: 0.5974 - val_loss: 1.6629\n",
      "Epoch 43/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7827 - loss: 0.4394 - val_accuracy: 0.6535 - val_loss: 1.3322\n",
      "Epoch 44/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8673 - loss: 0.2709 - val_accuracy: 0.6535 - val_loss: 1.6839\n",
      "Epoch 45/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.2067 - val_accuracy: 0.6832 - val_loss: 2.1436\n",
      "Epoch 46/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2006 - val_accuracy: 0.6568 - val_loss: 2.0568\n",
      "Epoch 47/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.1974 - val_accuracy: 0.6337 - val_loss: 2.0684\n",
      "Epoch 48/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8919 - loss: 0.2270 - val_accuracy: 0.6172 - val_loss: 1.9504\n",
      "Epoch 49/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9136 - loss: 0.2027 - val_accuracy: 0.6304 - val_loss: 2.0398\n",
      "Epoch 50/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8929 - loss: 0.2605 - val_accuracy: 0.6271 - val_loss: 2.1878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculer les pondérations des classes\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Créer le modèle\n",
    "model = create_bi_cnn_model(question_shape, answer_shape)\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    [q_train, a_train],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5944 - loss: 2.3541\n",
      "Test Accuracy: 0.6207650303840637\n"
     ]
    }
   ],
   "source": [
    "q_test, a_test, y_test = prepare_data(test_grouped_clean)\n",
    "\n",
    "# Évaluer le modèle\n",
    "test_loss, test_acc = model.evaluate([q_test, a_test], y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "most relevant a small electrically powered pump\n",
      "most relevant [[0.4466947 ]\n",
      " [0.9988192 ]\n",
      " [0.36432326]\n",
      " [0.4486041 ]]\n",
      "how a water pump works\n",
      "['pumps operate by some mechanism typically reciprocating or rotary and consume energy to perform mechanical work by moving the fluid', 'a small electrically powered pump', 'a large electrically driven pump electropump for waterworks near the hengsteysee germany ', 'a pump is a device that moves fluids liquids or gases or sometimes slurries by mechanical action']\n",
      "[1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def predict_most_relevant_answer(model, question_vec, answer_vecs, answers):\n",
    "    question_vec = np.expand_dims(np.array(question_vec), axis=0)  # (1, embedding_dimension)\n",
    "    question_vec = np.expand_dims(question_vec, axis=1)  # (1, 1, embedding_dimension)\n",
    "    \n",
    "    answer_vecs = np.expand_dims(np.array(answer_vecs), axis=1)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Répéter la question pour chaque réponse\n",
    "    q_data = np.repeat(question_vec, len(answer_vecs), axis=0)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Prédire les scores pour chaque réponse\n",
    "    predictions = model.predict([q_data, answer_vecs])\n",
    "    \n",
    "    # Trouver l'indice de la réponse avec la probabilité la plus élevée\n",
    "    most_relevant_index = np.argmax(predictions)\n",
    "    \n",
    "    # Retourner la réponse en string la plus pertinente\n",
    "    most_relevant_answer = answers[most_relevant_index]\n",
    "    \n",
    "    return most_relevant_answer, predictions\n",
    "\n",
    "# Exemple d'utilisation\n",
    "single_question_vec = test_grouped_clean.iloc[0]['question_vec']\n",
    "single_answer_vecs = test_grouped_clean.iloc[0]['answer_vecs']\n",
    "single_answers = test_grouped_clean.iloc[0]['answer']\n",
    "most_relevant_answer,predictions = predict_most_relevant_answer(model, single_question_vec, single_answer_vecs, single_answers)\n",
    "print(f'most relevant {most_relevant_answer}')\n",
    "print(f'most relevant {predictions}')\n",
    "print(test_grouped_clean.iloc[0]['question'])\n",
    "print(test_grouped_clean.iloc[0]['answer'])\n",
    "print(test_grouped_clean.iloc[0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_val, a_val, y_val = prepare_data(validation_grouped_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "MAP: 0.5793\n",
      "MRR: 0.5840\n",
      "Success@1: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NeilB\\AppData\\Local\\Temp\\ipykernel_18104\\3124251072.py:33: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
      "  true_indices = np.where(true_labels == 1)[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "q_val, a_val, y_val = prepare_data(validation_grouped_clean)\n",
    "\n",
    "def mean_reciprocal_rank(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR).\n",
    "\n",
    "    y_true: list of one-hot encoded true labels\n",
    "    y_pred: list of one-hot encoded predicted labels\n",
    "\n",
    "    Returns: Mean Reciprocal Rank (MRR)\n",
    "    \"\"\"\n",
    "    ranks = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_index = np.argmax(true_labels)\n",
    "        pred_sorted_indices = np.argsort(pred_labels)[::-1]\n",
    "        rank = np.where(pred_sorted_indices == true_index)[0][0] + 1  # Rank is 1-based\n",
    "        ranks.append(1 / rank)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Average Precision (MAP).\n",
    "\n",
    "    y_true: list of one-hot encoded true labels\n",
    "    y_pred: list of one-hot encoded predicted labels\n",
    "\n",
    "    Returns: Mean Average Precision (MAP)\n",
    "    \"\"\"\n",
    "    average_precisions = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_indices = np.where(true_labels == 1)[0]\n",
    "        pred_sorted_indices = np.argsort(pred_labels)[::-1]\n",
    "        precisions = []\n",
    "        num_correct = 0\n",
    "        for i, idx in enumerate(pred_sorted_indices):\n",
    "            if idx in true_indices:\n",
    "                num_correct += 1\n",
    "                precision = num_correct / (i + 1)\n",
    "                precisions.append(precision)\n",
    "        if precisions:\n",
    "            average_precisions.append(np.mean(precisions))\n",
    "    return np.mean(average_precisions)\n",
    "\n",
    "\n",
    "def success_at_1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Success@1 (S@1).\n",
    "\n",
    "    y_true: list of one-hot encoded true labels\n",
    "    y_pred: list of one-hot encoded predicted labels\n",
    "\n",
    "    Returns: Success@1 (S@1)\n",
    "    \"\"\"\n",
    "    successes = 0\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        if np.argmax(pred_labels) == np.argmax(true_labels):\n",
    "            successes += 1\n",
    "    return successes / len(y_true)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = []\n",
    "for q_vec, a_vecs in zip(validation_grouped_clean['question_vec'], validation_grouped_clean['answer_vecs']):\n",
    "    question_vec = np.expand_dims(np.array(q_vec), axis=0)  # (1, embedding_dimension)\n",
    "    question_vec = np.expand_dims(question_vec, axis=1)  # (1, 1, embedding_dimension)\n",
    "    \n",
    "    answer_vecs = np.expand_dims(np.array(a_vecs), axis=1)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Répéter la question pour chaque réponse\n",
    "    q_data = np.repeat(question_vec, len(answer_vecs), axis=0)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Prédire les scores pour chaque réponse\n",
    "    predictions = model.predict([q_data, answer_vecs])\n",
    "\n",
    "    y_pred.append(predictions)\n",
    "    \n",
    "\n",
    "y_pred_onehot = []\n",
    "for preds in y_pred:\n",
    "    one_hot = np.zeros(len(preds))\n",
    "    one_hot[np.argmax(preds)] = 1\n",
    "    y_pred_onehot.append(one_hot)\n",
    "\n",
    "\n",
    "# Calculate the metrics\n",
    "mrr = mean_reciprocal_rank(y_val, y_pred_onehot)\n",
    "map_score = mean_average_precision(y_val, y_pred_onehot)\n",
    "s_at_1 = success_at_1(y_val, y_pred_onehot)\n",
    "\n",
    "\n",
    "print(f'MAP: {map_score:.4f}')\n",
    "print(f'MRR: {mrr:.4f}')\n",
    "print(f'Success@1: {s_at_1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------+\n",
      "| Metric                       |   Score |\n",
      "+==============================+=========+\n",
      "| Mean Average Precision (MAP) |  0.5793 |\n",
      "+------------------------------+---------+\n",
      "| Mean Reciprocal Rank (MRR)   |  0.584  |\n",
      "+------------------------------+---------+\n",
      "| Success@1 (S@1)              |  0.1196 |\n",
      "+------------------------------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NeilB\\AppData\\Local\\Temp\\ipykernel_18104\\3124251072.py:33: DeprecationWarning: Calling nonzero on 0d arrays is deprecated, as it behaves surprisingly. Use `atleast_1d(cond).nonzero()` if the old behavior was intended. If the context of this warning is of the form `arr[nonzero(cond)]`, just use `arr[cond]`.\n",
      "  true_indices = np.where(true_labels == 1)[0]\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def display_results(map_score, mrr, s_at_1):\n",
    "    \"\"\"\n",
    "    Affiche les résultats dans un tableau formaté.\n",
    "    \n",
    "    map_score: float : Score MAP\n",
    "    mrr: float : Mean Reciprocal Rank\n",
    "    s_at_1: float : Success@1\n",
    "    \n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    headers = [\"Metric\", \"Score\"]\n",
    "    table = [\n",
    "        [\"Mean Average Precision (MAP)\", f\"{map_score:.4f}\"],\n",
    "        [\"Mean Reciprocal Rank (MRR)\", f\"{mrr:.4f}\"],\n",
    "        [\"Success@1 (S@1)\", f\"{s_at_1:.4f}\"]\n",
    "    ]\n",
    "    \n",
    "    print(tabulate(table, headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Calcul des métriques\n",
    "mrr = mean_reciprocal_rank(y_val, y_pred_onehot)\n",
    "map_score = mean_average_precision(y_val, y_pred_onehot)\n",
    "s_at_1 = success_at_1(y_val, y_pred_onehot)\n",
    "\n",
    "# Affichage des résultats\n",
    "display_results(map_score, mrr, s_at_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH FEATURES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_matching_features(df):\n",
    "    features = {\n",
    "        'length_answer': [[length(a) for a in answers] for answers in df['answer']],\n",
    "        'check_exact_match': [[check_exact_match(q, a) for a in answers] for q, answers in zip(df['question'], df['answer'])],\n",
    "        'overlap': [[overlap(q, a) for a in answers] for q, answers in zip(df['question'], df['answer'])],\n",
    "        'overlap_syn_fraction': [[overlap_syn_fraction(q, a) for a in answers] for q, answers in zip(df['question'], df['answer'])],\n",
    "        'tagme_overlap': [[tagme_overlap(q, a) for a in answers] for q, answers in zip(df['question'], df['answer'])],\n",
    "        'bm25_score': [[bm25_score(q, a, q + a) for a in answers] for q, answers in zip(df['question'], df['answer'])],\n",
    "        'word2vec_similarity': [[word2vec_similarity(q, a, word2vec_model) for a in answers] for q, answers in zip(df['question'], df['answer'])]\n",
    "    }\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "    # Calculer les features de lisibilité\n",
    "def calculate_readability_features(df):\n",
    "    features = {\n",
    "        'cpw_question': [[cpw(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'spw_question': [[spw(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'wps_question': [[wps(q)  for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'cwps_question': [[cwps(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'cwr_question': [[cwr(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'lwps_question': [[lwps(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'lwr_question': [[lwr(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'dale_chall_question': [[dale_chall(q) for x in df['answer'][i] ] for i,q in enumerate(df['question'])],\n",
    "        'cpw_answer': [[cpw(a) for a in answers] for answers in df['answer']],\n",
    "        'spw_answer': [[spw(a) for a in answers] for answers in df['answer']],\n",
    "        'wps_answer': [[wps(a) for a in answers] for answers in df['answer']],\n",
    "        'cwps_answer': [[cwps(a) for a in answers] for answers in df['answer']],\n",
    "        'cwr_answer': [[cwr(a) for a in answers] for answers in df['answer']],\n",
    "        'lwps_answer': [[lwps(a) for a in answers] for answers in df['answer']],\n",
    "        'lwr_answer': [[lwr(a) for a in answers] for answers in df['answer']],\n",
    "        'dale_chall_answer': [[dale_chall(a) for a in answers] for answers in df['answer']]\n",
    "    }\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Fusionner les fonctionnalités de lisibilité et de matching lexical\n",
    "def calculate_all_features(df):\n",
    "    readability_features = calculate_readability_features(df)\n",
    "    matching_features = calculate_matching_features(df)\n",
    "    return pd.concat([readability_features, matching_features], axis=1)\n",
    "\n",
    "# Calculer les fonctionnalités pour les ensembles de données groupés\n",
    "\n",
    "train_grouped_all_features = pd.concat([train_grouped_clean, calculate_all_features(train_grouped_clean)], axis=1)\n",
    "validation_grouped_all_features = pd.concat([validation_grouped_clean, calculate_all_features(validation_grouped_clean)], axis=1)\n",
    "test_grouped_all_features = pd.concat([test_grouped_clean, calculate_all_features(test_grouped_clean)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpw_question</th>\n",
       "      <th>spw_question</th>\n",
       "      <th>wps_question</th>\n",
       "      <th>cwps_question</th>\n",
       "      <th>cwr_question</th>\n",
       "      <th>lwps_question</th>\n",
       "      <th>lwr_question</th>\n",
       "      <th>dale_chall_question</th>\n",
       "      <th>cpw_answer</th>\n",
       "      <th>spw_answer</th>\n",
       "      <th>...</th>\n",
       "      <th>lwps_answer</th>\n",
       "      <th>lwr_answer</th>\n",
       "      <th>dale_chall_answer</th>\n",
       "      <th>length_answer</th>\n",
       "      <th>check_exact_match</th>\n",
       "      <th>overlap</th>\n",
       "      <th>overlap_syn_fraction</th>\n",
       "      <th>tagme_overlap</th>\n",
       "      <th>bm25_score</th>\n",
       "      <th>word2vec_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4.2, 4.2, 4.2, 4.2]</td>\n",
       "      <td>[1.4, 1.4, 1.4, 1.4]</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[7.04, 7.04, 7.04, 7.04]</td>\n",
       "      <td>[4.608695652173913, 4.75, 5.636363636363637, 4...</td>\n",
       "      <td>[1.4782608695652173, 1.5, 1.8181818181818181, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 0, 4, 0]</td>\n",
       "      <td>[0.08695652173913043, 0.0, 0.18181818181818182...</td>\n",
       "      <td>[10.27, 11.93, 10.47, 11.73]</td>\n",
       "      <td>[23, 8, 22, 4]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.2608695652173913, 0.0, 0.0, 0.5]</td>\n",
       "      <td>[0.2608695652173913, 0.0, 0.0, 0.5]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.1695319202612433, 0.0, 0.0, 3.425402019863292]</td>\n",
       "      <td>[0.7429044, 0.2997008, 0.5121894, 0.71078146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5.333333333333333, 5.333333333333333, 5.33333...</td>\n",
       "      <td>[1.6666666666666667, 1.6666666666666667, 1.666...</td>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "      <td>[11.83, 11.83, 11.83, 11.83]</td>\n",
       "      <td>[5.407407407407407, 5.5, 6.2, 4.4]</td>\n",
       "      <td>[1.7407407407407407, 2.0, 2.2, 1.8]</td>\n",
       "      <td>...</td>\n",
       "      <td>[6, 1, 2, 0]</td>\n",
       "      <td>[0.2222222222222222, 0.16666666666666666, 0.4,...</td>\n",
       "      <td>[10.82, 14.46, 10.2, 10.2]</td>\n",
       "      <td>[27, 6, 5, 5]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.037037037037037035, 0.16666666666666666, 0....</td>\n",
       "      <td>[0.1111111111111111, 0.3333333333333333, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.40768426907095634, 1.3706284736831396, 0.0,...</td>\n",
       "      <td>[0.7085388, 0.61963964, 0.2614088, 0.70052916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5.625, 5.625, 5.625, 5.625]</td>\n",
       "      <td>[1.625, 1.625, 1.625, 1.625]</td>\n",
       "      <td>[8, 8, 8, 8]</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[11.93, 11.93, 11.93, 11.93]</td>\n",
       "      <td>[5.392857142857143, 5.214285714285714, 5.375, ...</td>\n",
       "      <td>[1.8214285714285714, 1.5714285714285714, 1.75,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8, 4, 3, 6]</td>\n",
       "      <td>[0.2857142857142857, 0.2857142857142857, 0.375...</td>\n",
       "      <td>[11.79, 12.23, 13.9, 10.94]</td>\n",
       "      <td>[28, 14, 8, 20]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.07142857142857142, 0.375, 0.3]</td>\n",
       "      <td>[0.0, 0.07142857142857142, 0.375, 0.3]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.7068947195130464, 3.3614266532470127, ...</td>\n",
       "      <td>[0.5874782, 0.66302633, 0.51851976, 0.53118145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.8, 4.8, 4.8, 4.8]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[13.36, 13.36, 13.36, 13.36]</td>\n",
       "      <td>[3.6153846153846154, 5.333333333333333, 4.5714...</td>\n",
       "      <td>[1.0769230769230769, 1.4444444444444444, 1.714...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.1111111111111111, 0.14285714285714285,...</td>\n",
       "      <td>[7.93, 11.1, 10.75, 10.75]</td>\n",
       "      <td>[13, 9, 7, 7]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.23076923076923078, 0.2222222222222222, 0.0,...</td>\n",
       "      <td>[0.38461538461538464, 0.3333333333333333, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.9280123653507184, 1.7962903299676172, 0.0, ...</td>\n",
       "      <td>[0.8436012, 0.7371161, 0.39387175, 0.7742784]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.555555555555555, 4.555555555555555, 4.55555...</td>\n",
       "      <td>[1.3333333333333333, 1.3333333333333333, 1.333...</td>\n",
       "      <td>[9, 9, 9, 9]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.1111111111111111, 0.1111111111111111, 0.111...</td>\n",
       "      <td>[2, 2, 2, 2]</td>\n",
       "      <td>[0.2222222222222222, 0.2222222222222222, 0.222...</td>\n",
       "      <td>[7.59, 7.59, 7.59, 7.59]</td>\n",
       "      <td>[3.6222222222222222, 6.2, 4.277777777777778, 3...</td>\n",
       "      <td>[1.1333333333333333, 2.0, 1.3333333333333333, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[3, 2, 3, 1]</td>\n",
       "      <td>[0.06666666666666667, 0.4, 0.16666666666666666...</td>\n",
       "      <td>[8.32, 13.36, 10.67, 8.49]</td>\n",
       "      <td>[45, 5, 18, 36]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.28888888888888886, 0.0, 0.16666666666666666...</td>\n",
       "      <td>[0.28888888888888886, 0.2, 0.2777777777777778,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[3.0127938438548734, 0.0, 1.630096521347441, 3...</td>\n",
       "      <td>[0.82951623, 0.6748694, 0.7648825, 0.67787033]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>[4.1, 4.1, 4.1, 4.1]</td>\n",
       "      <td>[1.2, 1.2, 1.2, 1.2]</td>\n",
       "      <td>[10, 10, 10, 10]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5, 0.5, 0.5, 0.5]</td>\n",
       "      <td>[4.333333333333333, 4.647058823529412, 4.26666...</td>\n",
       "      <td>[1.393939393939394, 1.588235294117647, 1.3, 1....</td>\n",
       "      <td>...</td>\n",
       "      <td>[3, 3, 0, 1]</td>\n",
       "      <td>[0.09090909090909091, 0.17647058823529413, 0.0...</td>\n",
       "      <td>[11.02, 10.05, 8.28, 7.98]</td>\n",
       "      <td>[33, 17, 30, 8]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.30303030303030304, 0.0, 0.2, 0.125]</td>\n",
       "      <td>[0.30303030303030304, 0.0, 0.2, 0.125]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.8779980046473312, 0.0, 1.886943482451454, 1...</td>\n",
       "      <td>[0.68412364, 0.52145976, 0.6596721, 0.52316576]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>[4.4, 4.4, 4.4, 4.4]</td>\n",
       "      <td>[1.2, 1.2, 1.2, 1.2]</td>\n",
       "      <td>[5, 5, 5, 5]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[7.04, 7.04, 7.04, 7.04]</td>\n",
       "      <td>[4.090909090909091, 4.903225806451613, 4.87096...</td>\n",
       "      <td>[1.4090909090909092, 1.4516129032258065, 1.387...</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 4, 7, 2]</td>\n",
       "      <td>[0.09090909090909091, 0.12903225806451613, 0.2...</td>\n",
       "      <td>[9.75, 11.29, 12.31, 9.25]</td>\n",
       "      <td>[22, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.09090909090909091, 0.06451612903225806, 0.1...</td>\n",
       "      <td>[0.09090909090909091, 0.06451612903225806, 0.1...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.8828877500116982, 0.7007465180391069, 1.680...</td>\n",
       "      <td>[0.6410951, 0.5656551, 0.56021786, 0.59005773]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>[4.666666666666667, 4.666666666666667, 4.66666...</td>\n",
       "      <td>[1.3333333333333333, 1.3333333333333333, 1.333...</td>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[9.2, 9.2, 9.2, 9.2]</td>\n",
       "      <td>[4.8, 4.681818181818182, 4.882352941176471, 5....</td>\n",
       "      <td>[1.48, 1.5454545454545454, 1.3529411764705883,...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 4, 6, 4]</td>\n",
       "      <td>[0.04, 0.18181818181818182, 0.1176470588235294...</td>\n",
       "      <td>[9.93, 9.75, 14.84, 10.05]</td>\n",
       "      <td>[25, 22, 51, 17]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.2, 0.09090909090909091, 0.13725490196078433...</td>\n",
       "      <td>[0.2, 0.09090909090909091, 0.13725490196078433...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.06512396948112, 0.9272324284193261, 1.49084...</td>\n",
       "      <td>[0.79676664, 0.61080533, 0.5125874, 0.5055566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>[4.333333333333333, 4.333333333333333, 4.33333...</td>\n",
       "      <td>[1.3333333333333333, 1.3333333333333333, 1.333...</td>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.16666666666666666, 0.16666666666666666, 0.1...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[9.2, 9.2, 9.2, 9.2]</td>\n",
       "      <td>[4.44, 4.722222222222222, 5.130434782608695, 6...</td>\n",
       "      <td>[1.32, 1.5, 1.5217391304347827, 2.111111111111...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 3, 4, 3]</td>\n",
       "      <td>[0.16, 0.16666666666666666, 0.1739130434782608...</td>\n",
       "      <td>[11.82, 10.67, 10.27, 14.61]</td>\n",
       "      <td>[25, 18, 23, 9]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.2222222222222222, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.2222222222222222, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 2.168170744293496, 0.0, 0.0]</td>\n",
       "      <td>[0.4391217, 0.6505335, 0.48236465, 0.23116997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>[5.5, 5.5, 5.5, 5.5]</td>\n",
       "      <td>[1.25, 1.25, 1.25, 1.25]</td>\n",
       "      <td>[4, 4, 4, 4]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "      <td>[0.2, 0.2, 0.2, 0.2]</td>\n",
       "      <td>[6.153846153846154, 5.0, 4.9, 4.181818181818182]</td>\n",
       "      <td>[1.6923076923076923, 1.0, 1.4333333333333333, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4, 0, 5, 1]</td>\n",
       "      <td>[0.3076923076923077, 0.0, 0.16666666666666666,...</td>\n",
       "      <td>[9.14, 0.05, 11.44, 8.49]</td>\n",
       "      <td>[13, 1, 30, 11]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0.23076923076923078, 0.0, 0.0, 0.090909090909...</td>\n",
       "      <td>[0.23076923076923078, 0.0, 0.0, 0.090909090909...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.165937264229137, 0.0, 0.0, 0.7911279048523908]</td>\n",
       "      <td>[0.6919538, 0.13007106, 0.4283884, 0.434447]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cpw_question  \\\n",
       "0                                 [4.2, 4.2, 4.2, 4.2]   \n",
       "1    [5.333333333333333, 5.333333333333333, 5.33333...   \n",
       "2                         [5.625, 5.625, 5.625, 5.625]   \n",
       "3                                 [4.8, 4.8, 4.8, 4.8]   \n",
       "4    [4.555555555555555, 4.555555555555555, 4.55555...   \n",
       "..                                                 ...   \n",
       "751                               [4.1, 4.1, 4.1, 4.1]   \n",
       "752                               [4.4, 4.4, 4.4, 4.4]   \n",
       "753  [4.666666666666667, 4.666666666666667, 4.66666...   \n",
       "754  [4.333333333333333, 4.333333333333333, 4.33333...   \n",
       "755                               [5.5, 5.5, 5.5, 5.5]   \n",
       "\n",
       "                                          spw_question      wps_question  \\\n",
       "0                                 [1.4, 1.4, 1.4, 1.4]      [5, 5, 5, 5]   \n",
       "1    [1.6666666666666667, 1.6666666666666667, 1.666...      [6, 6, 6, 6]   \n",
       "2                         [1.625, 1.625, 1.625, 1.625]      [8, 8, 8, 8]   \n",
       "3                                 [1.0, 1.0, 1.0, 1.0]      [5, 5, 5, 5]   \n",
       "4    [1.3333333333333333, 1.3333333333333333, 1.333...      [9, 9, 9, 9]   \n",
       "..                                                 ...               ...   \n",
       "751                               [1.2, 1.2, 1.2, 1.2]  [10, 10, 10, 10]   \n",
       "752                               [1.2, 1.2, 1.2, 1.2]      [5, 5, 5, 5]   \n",
       "753  [1.3333333333333333, 1.3333333333333333, 1.333...      [6, 6, 6, 6]   \n",
       "754  [1.3333333333333333, 1.3333333333333333, 1.333...      [6, 6, 6, 6]   \n",
       "755                           [1.25, 1.25, 1.25, 1.25]      [4, 4, 4, 4]   \n",
       "\n",
       "    cwps_question                                       cwr_question  \\\n",
       "0    [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "1    [1, 1, 1, 1]  [0.16666666666666666, 0.16666666666666666, 0.1...   \n",
       "2    [2, 2, 2, 2]                           [0.25, 0.25, 0.25, 0.25]   \n",
       "3    [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "4    [1, 1, 1, 1]  [0.1111111111111111, 0.1111111111111111, 0.111...   \n",
       "..            ...                                                ...   \n",
       "751  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "752  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "753  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "754  [1, 1, 1, 1]  [0.16666666666666666, 0.16666666666666666, 0.1...   \n",
       "755  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "    lwps_question                                       lwr_question  \\\n",
       "0    [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "1    [1, 1, 1, 1]  [0.16666666666666666, 0.16666666666666666, 0.1...   \n",
       "2    [2, 2, 2, 2]                           [0.25, 0.25, 0.25, 0.25]   \n",
       "3    [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "4    [2, 2, 2, 2]  [0.2222222222222222, 0.2222222222222222, 0.222...   \n",
       "..            ...                                                ...   \n",
       "751  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "752  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "753  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "754  [0, 0, 0, 0]                               [0.0, 0.0, 0.0, 0.0]   \n",
       "755  [1, 1, 1, 1]                           [0.25, 0.25, 0.25, 0.25]   \n",
       "\n",
       "              dale_chall_question  \\\n",
       "0        [7.04, 7.04, 7.04, 7.04]   \n",
       "1    [11.83, 11.83, 11.83, 11.83]   \n",
       "2    [11.93, 11.93, 11.93, 11.93]   \n",
       "3    [13.36, 13.36, 13.36, 13.36]   \n",
       "4        [7.59, 7.59, 7.59, 7.59]   \n",
       "..                            ...   \n",
       "751          [0.5, 0.5, 0.5, 0.5]   \n",
       "752      [7.04, 7.04, 7.04, 7.04]   \n",
       "753          [9.2, 9.2, 9.2, 9.2]   \n",
       "754          [9.2, 9.2, 9.2, 9.2]   \n",
       "755          [0.2, 0.2, 0.2, 0.2]   \n",
       "\n",
       "                                            cpw_answer  \\\n",
       "0    [4.608695652173913, 4.75, 5.636363636363637, 4...   \n",
       "1                   [5.407407407407407, 5.5, 6.2, 4.4]   \n",
       "2    [5.392857142857143, 5.214285714285714, 5.375, ...   \n",
       "3    [3.6153846153846154, 5.333333333333333, 4.5714...   \n",
       "4    [3.6222222222222222, 6.2, 4.277777777777778, 3...   \n",
       "..                                                 ...   \n",
       "751  [4.333333333333333, 4.647058823529412, 4.26666...   \n",
       "752  [4.090909090909091, 4.903225806451613, 4.87096...   \n",
       "753  [4.8, 4.681818181818182, 4.882352941176471, 5....   \n",
       "754  [4.44, 4.722222222222222, 5.130434782608695, 6...   \n",
       "755   [6.153846153846154, 5.0, 4.9, 4.181818181818182]   \n",
       "\n",
       "                                            spw_answer  ...   lwps_answer  \\\n",
       "0    [1.4782608695652173, 1.5, 1.8181818181818181, ...  ...  [2, 0, 4, 0]   \n",
       "1                  [1.7407407407407407, 2.0, 2.2, 1.8]  ...  [6, 1, 2, 0]   \n",
       "2    [1.8214285714285714, 1.5714285714285714, 1.75,...  ...  [8, 4, 3, 6]   \n",
       "3    [1.0769230769230769, 1.4444444444444444, 1.714...  ...  [0, 1, 1, 1]   \n",
       "4    [1.1333333333333333, 2.0, 1.3333333333333333, ...  ...  [3, 2, 3, 1]   \n",
       "..                                                 ...  ...           ...   \n",
       "751  [1.393939393939394, 1.588235294117647, 1.3, 1....  ...  [3, 3, 0, 1]   \n",
       "752  [1.4090909090909092, 1.4516129032258065, 1.387...  ...  [2, 4, 7, 2]   \n",
       "753  [1.48, 1.5454545454545454, 1.3529411764705883,...  ...  [1, 4, 6, 4]   \n",
       "754  [1.32, 1.5, 1.5217391304347827, 2.111111111111...  ...  [4, 3, 4, 3]   \n",
       "755  [1.6923076923076923, 1.0, 1.4333333333333333, ...  ...  [4, 0, 5, 1]   \n",
       "\n",
       "                                            lwr_answer  \\\n",
       "0    [0.08695652173913043, 0.0, 0.18181818181818182...   \n",
       "1    [0.2222222222222222, 0.16666666666666666, 0.4,...   \n",
       "2    [0.2857142857142857, 0.2857142857142857, 0.375...   \n",
       "3    [0.0, 0.1111111111111111, 0.14285714285714285,...   \n",
       "4    [0.06666666666666667, 0.4, 0.16666666666666666...   \n",
       "..                                                 ...   \n",
       "751  [0.09090909090909091, 0.17647058823529413, 0.0...   \n",
       "752  [0.09090909090909091, 0.12903225806451613, 0.2...   \n",
       "753  [0.04, 0.18181818181818182, 0.1176470588235294...   \n",
       "754  [0.16, 0.16666666666666666, 0.1739130434782608...   \n",
       "755  [0.3076923076923077, 0.0, 0.16666666666666666,...   \n",
       "\n",
       "                dale_chall_answer     length_answer check_exact_match  \\\n",
       "0    [10.27, 11.93, 10.47, 11.73]    [23, 8, 22, 4]      [0, 0, 0, 0]   \n",
       "1      [10.82, 14.46, 10.2, 10.2]     [27, 6, 5, 5]      [0, 0, 0, 0]   \n",
       "2     [11.79, 12.23, 13.9, 10.94]   [28, 14, 8, 20]      [0, 0, 0, 0]   \n",
       "3      [7.93, 11.1, 10.75, 10.75]     [13, 9, 7, 7]      [0, 0, 0, 0]   \n",
       "4      [8.32, 13.36, 10.67, 8.49]   [45, 5, 18, 36]      [0, 0, 0, 0]   \n",
       "..                            ...               ...               ...   \n",
       "751    [11.02, 10.05, 8.28, 7.98]   [33, 17, 30, 8]      [0, 0, 0, 0]   \n",
       "752    [9.75, 11.29, 12.31, 9.25]  [22, 31, 31, 31]      [0, 0, 0, 0]   \n",
       "753    [9.93, 9.75, 14.84, 10.05]  [25, 22, 51, 17]      [0, 0, 0, 0]   \n",
       "754  [11.82, 10.67, 10.27, 14.61]   [25, 18, 23, 9]      [0, 0, 0, 0]   \n",
       "755     [9.14, 0.05, 11.44, 8.49]   [13, 1, 30, 11]      [0, 0, 0, 0]   \n",
       "\n",
       "                                               overlap  \\\n",
       "0                  [0.2608695652173913, 0.0, 0.0, 0.5]   \n",
       "1    [0.037037037037037035, 0.16666666666666666, 0....   \n",
       "2               [0.0, 0.07142857142857142, 0.375, 0.3]   \n",
       "3    [0.23076923076923078, 0.2222222222222222, 0.0,...   \n",
       "4    [0.28888888888888886, 0.0, 0.16666666666666666...   \n",
       "..                                                 ...   \n",
       "751             [0.30303030303030304, 0.0, 0.2, 0.125]   \n",
       "752  [0.09090909090909091, 0.06451612903225806, 0.1...   \n",
       "753  [0.2, 0.09090909090909091, 0.13725490196078433...   \n",
       "754                [0.0, 0.2222222222222222, 0.0, 0.0]   \n",
       "755  [0.23076923076923078, 0.0, 0.0, 0.090909090909...   \n",
       "\n",
       "                                  overlap_syn_fraction         tagme_overlap  \\\n",
       "0                  [0.2608695652173913, 0.0, 0.0, 0.5]  [0.0, 0.0, 0.0, 0.0]   \n",
       "1    [0.1111111111111111, 0.3333333333333333, 0.0, ...  [0.0, 0.0, 0.0, 0.0]   \n",
       "2               [0.0, 0.07142857142857142, 0.375, 0.3]  [0.0, 0.0, 0.0, 0.0]   \n",
       "3    [0.38461538461538464, 0.3333333333333333, 0.0,...  [0.0, 0.0, 0.0, 0.0]   \n",
       "4    [0.28888888888888886, 0.2, 0.2777777777777778,...  [0.0, 0.0, 0.0, 0.0]   \n",
       "..                                                 ...                   ...   \n",
       "751             [0.30303030303030304, 0.0, 0.2, 0.125]  [0.0, 0.0, 0.0, 0.0]   \n",
       "752  [0.09090909090909091, 0.06451612903225806, 0.1...  [0.0, 0.0, 0.0, 0.0]   \n",
       "753  [0.2, 0.09090909090909091, 0.13725490196078433...  [1.0, 0.0, 0.0, 0.0]   \n",
       "754                [0.0, 0.2222222222222222, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0]   \n",
       "755  [0.23076923076923078, 0.0, 0.0, 0.090909090909...  [1.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                            bm25_score  \\\n",
       "0    [2.1695319202612433, 0.0, 0.0, 3.425402019863292]   \n",
       "1    [0.40768426907095634, 1.3706284736831396, 0.0,...   \n",
       "2    [0.0, 0.7068947195130464, 3.3614266532470127, ...   \n",
       "3    [1.9280123653507184, 1.7962903299676172, 0.0, ...   \n",
       "4    [3.0127938438548734, 0.0, 1.630096521347441, 3...   \n",
       "..                                                 ...   \n",
       "751  [2.8779980046473312, 0.0, 1.886943482451454, 1...   \n",
       "752  [0.8828877500116982, 0.7007465180391069, 1.680...   \n",
       "753  [2.06512396948112, 0.9272324284193261, 1.49084...   \n",
       "754                 [0.0, 2.168170744293496, 0.0, 0.0]   \n",
       "755  [2.165937264229137, 0.0, 0.0, 0.7911279048523908]   \n",
       "\n",
       "                                 word2vec_similarity  \n",
       "0      [0.7429044, 0.2997008, 0.5121894, 0.71078146]  \n",
       "1     [0.7085388, 0.61963964, 0.2614088, 0.70052916]  \n",
       "2    [0.5874782, 0.66302633, 0.51851976, 0.53118145]  \n",
       "3      [0.8436012, 0.7371161, 0.39387175, 0.7742784]  \n",
       "4     [0.82951623, 0.6748694, 0.7648825, 0.67787033]  \n",
       "..                                               ...  \n",
       "751  [0.68412364, 0.52145976, 0.6596721, 0.52316576]  \n",
       "752   [0.6410951, 0.5656551, 0.56021786, 0.59005773]  \n",
       "753   [0.79676664, 0.61080533, 0.5125874, 0.5055566]  \n",
       "754   [0.4391217, 0.6505335, 0.48236465, 0.23116997]  \n",
       "755     [0.6919538, 0.13007106, 0.4283884, 0.434447]  \n",
       "\n",
       "[756 rows x 23 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = [\n",
    "    'cpw_question', 'spw_question', 'wps_question', 'cwps_question',\n",
    "    'cwr_question', 'lwps_question', 'lwr_question', 'dale_chall_question',\n",
    "    'cpw_answer', 'spw_answer', 'wps_answer', 'cwps_answer', 'cwr_answer',\n",
    "    'lwps_answer', 'lwr_answer', 'dale_chall_answer', 'length_answer',\n",
    "    'check_exact_match', 'overlap', 'overlap_syn_fraction', 'tagme_overlap',\n",
    "    'bm25_score', 'word2vec_similarity'\n",
    "]\n",
    "\n",
    "# Extract the features\n",
    "features = train_grouped_all_features[features_list]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_train shape: (3024, 1, 300)\n",
      "a_train shape: (3024, 1, 300)\n",
      "y_train shape: (3024,)\n",
      "features_train shape: (3024, 23)\n"
     ]
    }
   ],
   "source": [
    "def extract_features(row):\n",
    "    feature_row = []\n",
    "    for col in [\n",
    "        'cpw_question', 'spw_question', 'wps_question', 'cwps_question',\n",
    "        'cwr_question', 'lwps_question', 'lwr_question', 'dale_chall_question',\n",
    "        'cpw_answer', 'spw_answer', 'wps_answer', 'cwps_answer', 'cwr_answer',\n",
    "        'lwps_answer', 'lwr_answer', 'dale_chall_answer', 'length_answer',\n",
    "        'check_exact_match', 'overlap', 'overlap_syn_fraction', 'tagme_overlap',\n",
    "        'bm25_score', 'word2vec_similarity'\n",
    "    ]:\n",
    "        feature_row.append(row[col])\n",
    "    return np.array(feature_row)\n",
    "\n",
    "train_grouped_clean['features'] = train_grouped_all_features.apply(extract_features, axis=1)\n",
    "validation_grouped_clean['features'] = validation_grouped_all_features.apply(extract_features, axis=1)\n",
    "test_grouped_clean['features'] = test_grouped_all_features.apply(extract_features, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(df):\n",
    "    q_data = []\n",
    "    a_data = []\n",
    "    y_data = []\n",
    "    features_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        question_vec = np.array(row['question_vec'])\n",
    "        answer_vecs = np.array(row['answer_vecs'])\n",
    "        labels = row['label']\n",
    "        features = np.array(row['features']).reshape(len(labels), -1)  # Ensure features are properly shaped\n",
    "\n",
    "        num_answers = len(answer_vecs)\n",
    "        q_data.extend([question_vec] * num_answers)\n",
    "        a_data.extend(answer_vecs)\n",
    "        y_data.extend(labels)\n",
    "        features_data.extend(features)\n",
    "\n",
    "    q_data = np.expand_dims(np.array(q_data), axis=1)  # Add an axis for the sequence\n",
    "    a_data = np.expand_dims(np.array(a_data), axis=1)  # Add an axis for the sequence\n",
    "    y_data = np.array(y_data)\n",
    "    features_data = np.array(features_data)\n",
    "\n",
    "    return q_data, a_data, y_data, features_data\n",
    "\n",
    "q_train, a_train, y_train, features_train = prepare_data(train_grouped_clean)\n",
    "q_val, a_val, y_val, features_val = prepare_data(validation_grouped_clean)\n",
    "q_test, a_test, y_test, features_test = prepare_data(test_grouped_clean)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f'q_train shape: {q_train.shape}')\n",
    "print(f'a_train shape: {a_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'features_train shape: {features_train.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_shape: (1, 300)\n",
      "answer_shape: (1, 300)\n",
      "num_features: 23\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_177\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_177\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_216     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_217     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │ input_layer_216[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ input_layer_217[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │ conv1d_115[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ conv1d_115[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">50,100</span> │ conv1d_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ conv1d_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_110     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_218     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_111     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">223</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_110[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_layer_218[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,344</span> │ concatenate_111[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_89          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_177[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ dropout_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_216     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_217     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_115 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m30,100\u001b[0m │ input_layer_216[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ input_layer_217[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_116 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m30,100\u001b[0m │ conv1d_115[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ conv1d_115[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_117 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │     \u001b[38;5;34m50,100\u001b[0m │ conv1d_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ conv1d_116[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv1d_117[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_110     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_218     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_111     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m223\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_110[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_layer_218[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_177 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m57,344\u001b[0m │ concatenate_111[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_89          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_177[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ dropout_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,901</span> (655.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m167,901\u001b[0m (655.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,901</span> (655.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m167,901\u001b[0m (655.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def create_bi_cnn_model(question_shape, answer_shape, num_features=None):\n",
    "    # Define question input\n",
    "    question_input = layers.Input(shape=question_shape)\n",
    "    answer_input = layers.Input(shape=answer_shape)\n",
    "    \n",
    "    # First convolutional layer with kernel size of 1\n",
    "    conv1 = layers.Conv1D(100, kernel_size=1, activation='tanh')\n",
    "    \n",
    "    # Second convolutional layer with kernel size of 3\n",
    "    conv2 = layers.Conv1D(100, kernel_size=3, activation='tanh', padding='same')\n",
    "    \n",
    "    # Third convolutional layer with kernel size of 5\n",
    "    conv3 = layers.Conv1D(100, kernel_size=5, activation='tanh', padding='same')\n",
    "    \n",
    "    # Process question and answer vectors through multiple convolutional layers\n",
    "    q_conv1 = conv1(question_input)\n",
    "    q_conv2 = conv2(q_conv1)\n",
    "    q_conv3 = conv3(q_conv2)\n",
    "    \n",
    "    a_conv1 = conv1(answer_input)\n",
    "    a_conv2 = conv2(a_conv1)\n",
    "    a_conv3 = conv3(a_conv2)\n",
    "    \n",
    "    # Max pooling\n",
    "    q_pool = layers.GlobalMaxPooling1D()(q_conv3)\n",
    "    a_pool = layers.GlobalMaxPooling1D()(a_conv3)\n",
    "    \n",
    "    # Concatenate pooled outputs\n",
    "    combined = layers.Concatenate()([q_pool, a_pool])\n",
    "    \n",
    "    if num_features is not None:\n",
    "        # Add the additional features if available\n",
    "        external_features = layers.Input(shape=(num_features,))\n",
    "        combined_with_features = layers.Concatenate()([combined, external_features])\n",
    "        \n",
    "        # Fully connected layer\n",
    "        dense = layers.Dense(256, activation='relu')(combined_with_features)\n",
    "        dropout = layers.Dropout(0.5)(dense)\n",
    "        output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = models.Model(inputs=[question_input, answer_input, external_features], outputs=output)\n",
    "    else:\n",
    "        # Fully connected layer\n",
    "        dense = layers.Dense(256, activation='relu')(combined)\n",
    "        dropout = layers.Dropout(0.5)(dense)\n",
    "        output = layers.Dense(1, activation='sigmoid')(dropout)\n",
    "        \n",
    "        # Create and compile the model\n",
    "        model = models.Model(inputs=[question_input, answer_input], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Determine the shapes of the inputs\n",
    "question_shape = (q_train.shape[1], q_train.shape[2])  # (sequence_length, embedding_dimension)\n",
    "answer_shape = (a_train.shape[1], a_train.shape[2])    # (sequence_length, embedding_dimension)\n",
    "num_features = features_train.shape[1]\n",
    "\n",
    "print(f'question_shape: {question_shape}')\n",
    "print(f'answer_shape: {answer_shape}')\n",
    "print(f'num_features: {num_features}')\n",
    "\n",
    "model = create_bi_cnn_model(question_shape, answer_shape, num_features)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8263 - loss: 0.8011 - val_accuracy: 0.8630 - val_loss: 0.8652\n",
      "Epoch 2/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9242 - loss: 0.2874 - val_accuracy: 0.8565 - val_loss: 0.9529\n",
      "Epoch 3/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2612 - val_accuracy: 0.8630 - val_loss: 1.1130\n",
      "Epoch 4/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9405 - loss: 0.1639 - val_accuracy: 0.8652 - val_loss: 1.1175\n",
      "Epoch 5/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1452 - val_accuracy: 0.8630 - val_loss: 1.1919\n",
      "Epoch 6/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.1583 - val_accuracy: 0.8609 - val_loss: 1.2887\n",
      "Epoch 7/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1149 - val_accuracy: 0.8739 - val_loss: 1.4369\n",
      "Epoch 8/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1166 - val_accuracy: 0.8696 - val_loss: 1.4498\n",
      "Epoch 9/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0995 - val_accuracy: 0.8522 - val_loss: 1.5730\n",
      "Epoch 10/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0866 - val_accuracy: 0.8522 - val_loss: 1.7496\n",
      "Epoch 11/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0687 - val_accuracy: 0.8761 - val_loss: 1.8291\n",
      "Epoch 12/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0598 - val_accuracy: 0.8239 - val_loss: 2.1411\n",
      "Epoch 13/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0725 - val_accuracy: 0.8326 - val_loss: 2.0761\n",
      "Epoch 14/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0603 - val_accuracy: 0.8565 - val_loss: 2.2075\n",
      "Epoch 15/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0478 - val_accuracy: 0.8652 - val_loss: 2.2442\n",
      "Epoch 16/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0381 - val_accuracy: 0.8652 - val_loss: 2.3112\n",
      "Epoch 17/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0355 - val_accuracy: 0.8065 - val_loss: 2.5462\n",
      "Epoch 18/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0685 - val_accuracy: 0.8609 - val_loss: 2.6650\n",
      "Epoch 19/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0250 - val_accuracy: 0.8609 - val_loss: 2.7434\n",
      "Epoch 20/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0154 - val_accuracy: 0.8652 - val_loss: 2.8050\n",
      "Epoch 21/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0307 - val_accuracy: 0.8696 - val_loss: 2.9868\n",
      "Epoch 22/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0317 - val_accuracy: 0.8674 - val_loss: 2.9889\n",
      "Epoch 23/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.8543 - val_loss: 2.9567\n",
      "Epoch 24/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0284 - val_accuracy: 0.8543 - val_loss: 3.2094\n",
      "Epoch 25/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0283 - val_accuracy: 0.8565 - val_loss: 3.2529\n",
      "Epoch 26/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0290 - val_accuracy: 0.8630 - val_loss: 3.1587\n",
      "Epoch 27/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0246 - val_accuracy: 0.8587 - val_loss: 3.1937\n",
      "Epoch 28/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0097 - val_accuracy: 0.8435 - val_loss: 3.2887\n",
      "Epoch 29/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0231 - val_accuracy: 0.8391 - val_loss: 3.3682\n",
      "Epoch 30/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0324 - val_accuracy: 0.8500 - val_loss: 3.3808\n",
      "Epoch 31/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0172 - val_accuracy: 0.8543 - val_loss: 3.4066\n",
      "Epoch 32/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.8478 - val_loss: 3.6435\n",
      "Epoch 33/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0534 - val_accuracy: 0.8630 - val_loss: 3.6433\n",
      "Epoch 34/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0101 - val_accuracy: 0.8587 - val_loss: 3.6965\n",
      "Epoch 35/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.8630 - val_loss: 3.9337\n",
      "Epoch 36/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0136 - val_accuracy: 0.8739 - val_loss: 3.8296\n",
      "Epoch 37/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0350 - val_accuracy: 0.8630 - val_loss: 3.9512\n",
      "Epoch 38/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.8630 - val_loss: 4.1396\n",
      "Epoch 39/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.8630 - val_loss: 4.2130\n",
      "Epoch 40/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.8565 - val_loss: 4.4029\n",
      "Epoch 41/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.8652 - val_loss: 4.2618\n",
      "Epoch 42/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0084 - val_accuracy: 0.8609 - val_loss: 4.2975\n",
      "Epoch 43/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0065 - val_accuracy: 0.8587 - val_loss: 4.3106\n",
      "Epoch 44/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0057 - val_accuracy: 0.8630 - val_loss: 4.3966\n",
      "Epoch 45/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0034 - val_accuracy: 0.8652 - val_loss: 4.7031\n",
      "Epoch 46/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.8609 - val_loss: 4.8128\n",
      "Epoch 47/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8609 - val_loss: 4.9033\n",
      "Epoch 48/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0220 - val_accuracy: 0.8522 - val_loss: 4.6982\n",
      "Epoch 49/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0181 - val_accuracy: 0.8413 - val_loss: 4.7597\n",
      "Epoch 50/50\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0249 - val_accuracy: 0.8696 - val_loss: 4.4781\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 3.4901\n",
      "Test Loss: 3.9432\n",
      "Test Accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [q_train, a_train, features_train],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=([q_val, a_val, features_val], y_val),\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate([q_test, a_test, features_test], y_test)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (1, 1, 300)\n",
      "q_data shape = (1, 1, 300)\n",
      "features_data shape = (1, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (1, 1, 300)\n",
      "q_data shape = (1, 1, 300)\n",
      "features_data shape = (1, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (1, 1, 300)\n",
      "q_data shape = (1, 1, 300)\n",
      "features_data shape = (1, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (1, 1, 300)\n",
      "q_data shape = (1, 1, 300)\n",
      "features_data shape = (1, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "answer_vecs shape = (2, 1, 300)\n",
      "q_data shape = (2, 1, 300)\n",
      "features_data shape = (2, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "answer_vecs shape = (3, 1, 300)\n",
      "q_data shape = (3, 1, 300)\n",
      "features_data shape = (3, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "answer_vecs shape = (4, 1, 300)\n",
      "q_data shape = (4, 1, 300)\n",
      "features_data shape = (4, 23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n",
      "0      [1, 1, 0, 0]\n",
      "1      [1, 0, 0, 0]\n",
      "2      [1, 0, 0, 0]\n",
      "3      [1, 0, 0, 0]\n",
      "4      [1, 0, 0, 0]\n",
      "           ...     \n",
      "120    [1, 0, 0, 0]\n",
      "121    [1, 0, 0, 0]\n",
      "122       [1, 0, 0]\n",
      "123    [1, 0, 0, 0]\n",
      "124    [1, 1, 0, 0]\n",
      "Name: label, Length: 125, dtype: object\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[567], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(predictions)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Calculate the metrics\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m mrr \u001b[38;5;241m=\u001b[39m \u001b[43mmean_reciprocal_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_grouped_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m map_score \u001b[38;5;241m=\u001b[39m mean_average_precision(validation_grouped_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred)\n\u001b[0;32m     65\u001b[0m s_at_1 \u001b[38;5;241m=\u001b[39m success_at_1(validation_grouped_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred)\n",
      "Cell \u001b[1;32mIn[567], line 13\u001b[0m, in \u001b[0;36mmean_reciprocal_rank\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     11\u001b[0m     sorted_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(pred)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_true)\n\u001b[1;32m---> 13\u001b[0m     rank \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m     ranks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m rank)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(ranks)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "q_val, a_val, y_val, features_val = prepare_data(validation_grouped_clean)\n",
    "\n",
    "\n",
    "def mean_reciprocal_rank(y_true, y_pred):\n",
    "    \"\"\"Compute the Mean Reciprocal Rank (MRR)\"\"\"\n",
    "    ranks = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        sorted_pred = np.argsort(pred)[::-1]\n",
    "        print(y_true)\n",
    "        rank = np.where(sorted_pred == true)[0][0] + 1\n",
    "        ranks.append(1 / rank)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "def mean_average_precision(y_true, y_pred):\n",
    "    \"\"\"Compute the Mean Average Precision (MAP)\"\"\"\n",
    "    average_precisions = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        sorted_pred = np.argsort(pred)[::-1]\n",
    "        hits = 0\n",
    "        sum_precisions = 0\n",
    "        for i, p in enumerate(sorted_pred):\n",
    "            if p == true:\n",
    "                hits += 1\n",
    "                sum_precisions += hits / (i + 1)\n",
    "        average_precisions.append(sum_precisions / hits if hits > 0 else 0)\n",
    "    return np.mean(average_precisions)\n",
    "\n",
    "def success_at_1(y_true, y_pred):\n",
    "    \"\"\"Compute the Success@1 (S@1)\"\"\"\n",
    "    successes = 0\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if np.argmax(pred) == true:\n",
    "            successes += 1\n",
    "    return successes / len(y_true)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = []\n",
    "for q_vec, a_vecs, features in zip(validation_grouped_clean['question_vec'], validation_grouped_clean['answer_vecs'], validation_grouped_clean['features']):\n",
    "    question_vec = np.expand_dims(np.array(q_vec), axis=0)  # (1, embedding_dimension)\n",
    "    question_vec = np.expand_dims(question_vec, axis=1)  # (1, 1, embedding_dimension)\n",
    "    \n",
    "    answer_vecs = np.expand_dims(np.array(a_vecs), axis=1)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Repeat the question for each answer\n",
    "    q_data = np.repeat(question_vec, len(answer_vecs), axis=0)  # (number_of_answers, 1, embedding_dimension)\n",
    "    \n",
    "    # Extract the corresponding features for each answer\n",
    "    features_data = np.expand_dims(features, axis=1)\n",
    "    features_data = np.array(features).reshape(len(answer_vecs), -1)\n",
    "    \n",
    "    print(f\"answer_vecs shape = {answer_vecs.shape}\")\n",
    "    print(f\"q_data shape = {q_data.shape}\")\n",
    "    print(f\"features_data shape = {features_data.shape}\")\n",
    "    \n",
    "    # Predict scores for each answer\n",
    "    predictions = model.predict([q_data, answer_vecs, features_data])\n",
    "    y_pred.append(predictions)\n",
    "\n",
    "# Calculate the metrics\n",
    "mrr = mean_reciprocal_rank(validation_grouped_clean['label'], y_pred)\n",
    "map_score = mean_average_precision(validation_grouped_clean['label'], y_pred)\n",
    "s_at_1 = success_at_1(validation_grouped_clean['label'], y_pred)\n",
    "\n",
    "\n",
    "print(f'MAP: {map_score:.4f}')\n",
    "print(f'MRR: {mrr:.4f}')\n",
    "print(f'Success@1: {s_at_1:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
