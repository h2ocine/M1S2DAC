{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NeilB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NeilB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'overlap' from 'features' (d:\\études\\pldac\\M1S2DAC\\RITAL\\projet-ri\\features.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cpw,spw,wps,cwps,cwr,lwps,lwr,dale_chall,length,check_exact_match,overlap,overlap_syn_fraction,tagme_overlap,bm25_score,word2vec_similarity\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'overlap' from 'features' (d:\\études\\pldac\\M1S2DAC\\RITAL\\projet-ri\\features.py)"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from datasets import load_from_disk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "from utils import preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "from features import cpw,spw,wps,cwps,cwr,lwps,lwr,dale_chall,length,check_exact_match,overlap,overlap_syn_fraction,tagme_overlap,bm25_score,word2vec_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Télécharger les embeddings Word2Vec pré-entraînés\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des des données et Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiqa_data = load_from_disk(\"wikiqa\")\n",
    "test_data_set = wikiqa_data[\"test\"]\n",
    "train_data_set = wikiqa_data[\"train\"]\n",
    "validation_data_set = wikiqa_data[\"validation\"]\n",
    "\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "    examples['question'] = [preprocess(q) for q in examples['question']]\n",
    "    examples['answer'] = [preprocess(a) for a in examples['answer']]\n",
    "    return examples\n",
    "\n",
    "train_data_set = train_data_set.map(preprocess_examples, batched=True)\n",
    "validation_data_set = validation_data_set.map(preprocess_examples, batched=True)\n",
    "test_data_set = test_data_set.map(preprocess_examples, batched=True)\n",
    "\n",
    "# Convertir en DataFrame\n",
    "train_df = pd.DataFrame({\n",
    "    'question': train_data_set['question'],\n",
    "    'answer': train_data_set['answer'],\n",
    "    'label': train_data_set['label']\n",
    "})\n",
    "\n",
    "validation_df = pd.DataFrame({\n",
    "    'question': validation_data_set['question'],\n",
    "    'answer': validation_data_set['answer'],\n",
    "    'label': validation_data_set['label']\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'question': test_data_set['question'],\n",
    "    'answer': test_data_set['answer'],\n",
    "    'label': test_data_set['label']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble de données d'entraînement :\n",
      "label\n",
      "0    19320\n",
      "1    19320\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ensemble de données de validation :\n",
      "label\n",
      "0    2593\n",
      "1    2593\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ensemble de données de test :\n",
      "label\n",
      "0    5872\n",
      "1    5872\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sur-échantillonner la classe minoritaire\n",
    "def balance_classes(df):\n",
    "    df_majority = df[df.label == 0]\n",
    "    df_minority = df[df.label == 1]\n",
    "    \n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # échantillonner avec remplacement\n",
    "                                     n_samples=len(df_majority),    # pour faire correspondre la classe majoritaire\n",
    "                                     random_state=123) # pour la reproductibilité\n",
    "    \n",
    "    return pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "balanced_train_df = balance_classes(train_df)\n",
    "balanced_validation_df = balance_classes(validation_df)\n",
    "balanced_test_df = balance_classes(test_df)\n",
    "\n",
    "# Afficher les statistiques des ensembles de données après suréchantillonnage\n",
    "print(\"Ensemble de données d'entraînement :\")\n",
    "print(balanced_train_df['label'].value_counts())\n",
    "print(\"\\nEnsemble de données de validation :\")\n",
    "print(balanced_validation_df['label'].value_counts())\n",
    "print(\"\\nEnsemble de données de test :\")\n",
    "print(balanced_test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble de données d'entraînement :\n",
      "label\n",
      "0    4830\n",
      "1    4830\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ensemble de données de validation :\n",
      "label\n",
      "0    648\n",
      "1    648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ensemble de données de test :\n",
      "label\n",
      "0    1468\n",
      "1    1468\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Réduire la classe majoritaire et suréchantillonner la classe minoritaire\n",
    "def reduce_and_balance_classes(df):\n",
    "    df_majority = df[df.label == 0]\n",
    "    df_minority = df[df.label == 1]\n",
    "    \n",
    "    # Réduire la classe majoritaire de 75 %\n",
    "    df_majority_reduced = resample(df_majority, \n",
    "                                   replace=False,    # échantillonner sans remplacement\n",
    "                                   n_samples=int(len(df_majority) * 0.25),  # 25 % de la classe majoritaire\n",
    "                                   random_state=123) # pour la reproductibilité\n",
    "    \n",
    "    # Suréchantillonner la classe minoritaire pour correspondre à la taille de la classe majoritaire réduite\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # échantillonner avec remplacement\n",
    "                                     n_samples=len(df_majority_reduced),    # pour faire correspondre la classe majoritaire réduite\n",
    "                                     random_state=123) # pour la reproductibilité\n",
    "    \n",
    "    return pd.concat([df_majority_reduced, df_minority_upsampled])\n",
    "\n",
    "balanced_train_df = reduce_and_balance_classes(train_df)\n",
    "balanced_validation_df = reduce_and_balance_classes(validation_df)\n",
    "balanced_test_df = reduce_and_balance_classes(test_df)\n",
    "\n",
    "# Afficher les statistiques des ensembles de données après réduction et suréchantillonnage\n",
    "print(\"Ensemble de données d'entraînement :\")\n",
    "print(balanced_train_df['label'].value_counts())\n",
    "print(\"\\nEnsemble de données de validation :\")\n",
    "print(balanced_validation_df['label'].value_counts())\n",
    "print(\"\\nEnsemble de données de test :\")\n",
    "print(balanced_test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_df = balanced_train_df.sample(frac=1).reset_index(drop=True)\n",
    "balanced_validation_df = balanced_validation_df.sample(frac=1).reset_index(drop=True)\n",
    "balanced_test_df = balanced_test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir le vecteur moyen de Word2Vec pour un texte donné\n",
    "def get_mean_word2vec(text, model):\n",
    "    words = text.split()\n",
    "    word_vecs = [model[word] for word in words if word in model]\n",
    "    if len(word_vecs) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "# Transformer les questions en vecteurs Word2Vec moyens\n",
    "def transform_questions(df, model):\n",
    "    return np.vstack(df['question'].apply(lambda x: get_mean_word2vec(x, model)).values)\n",
    "\n",
    "# Transformer les réponses en vecteurs Word2Vec moyens\n",
    "def transform_answers(df, model):\n",
    "    return np.vstack(df['answer'].apply(lambda x: get_mean_word2vec(x, model)).values)\n",
    "\n",
    "# Ajouter les nouvelles fonctionnalités pour les questions et les réponses\n",
    "def transform_length_answer(df):\n",
    "    return np.array(df['answer'].apply(length).values).reshape(-1, 1)\n",
    "\n",
    "def transform_exact_match(df):\n",
    "    return np.array(df.apply(lambda row: check_exact_match(row['question'], row['answer']), axis=1)).reshape(-1, 1)\n",
    "\n",
    "def transform_overlap(df):\n",
    "    return np.array(df.apply(lambda row: overlap(row['question'], row['answer']), axis=1)).reshape(-1, 1)\n",
    "\n",
    "def transform_overlap_syn(df):\n",
    "    return np.array(df.apply(lambda row: overlap_syn_fraction(row['question'], row['answer']), axis=1)).reshape(-1, 1)\n",
    "\n",
    "def transform_tagme(df):\n",
    "    return np.array(df.apply(lambda row: tagme_overlap(row['question'], row['answer']), axis=1)).reshape(-1, 1)\n",
    "\n",
    "def transform_w2v_sim(df, model):\n",
    "    return np.array(df.apply(lambda row: word2vec_similarity(row['question'], row['answer'], model), axis=1)).reshape(-1, 1)\n",
    "\n",
    "# Transformer les questions en vecteurs Word2Vec moyens\n",
    "def transform_questions(df, model):\n",
    "    return np.vstack(df['question'].apply(lambda x: get_mean_word2vec(x, model)).values)\n",
    "\n",
    "# Transformer les réponses en vecteurs Word2Vec moyens\n",
    "def transform_answers(df, model):\n",
    "    return np.vstack(df['answer'].apply(lambda x: get_mean_word2vec(x, model)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour PyTorch\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, word2vec_model):\n",
    "        self.labels = df['label'].values\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "        self.features = np.hstack([\n",
    "            transform_questions(df, word2vec_model),\n",
    "            transform_answers(df, word2vec_model),\n",
    "            transform_length_answer(df),\n",
    "            transform_exact_match(df),\n",
    "            transform_overlap(df),\n",
    "            transform_overlap_syn(df),\n",
    "            transform_tagme(df),\n",
    "            transform_w2v_sim(df, word2vec_model),\n",
    "\n",
    "        ])\n",
    "\n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Créer les datasets\n",
    "train_dataset = QADataset(balanced_train_df, word2vec_model)\n",
    "validation_dataset = QADataset(balanced_validation_df, word2vec_model)\n",
    "test_dataset = QADataset(balanced_test_df, word2vec_model)\n",
    "\n",
    "# Créer les DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QACNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(QACNN, self).__init__()\n",
    "#         # Convolution Layer 1\n",
    "#         self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        \n",
    "#         # Convolution Layer 2\n",
    "#         self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "#         # Max Pooling Layer\n",
    "#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "#         # Fully Connected Layer 1\n",
    "#         self.fc1 = nn.Linear(128 * (input_dim // 2 // 2), 128)\n",
    "        \n",
    "#         # Fully Connected Layer 2 (Output Layer)\n",
    "#         self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "#         # Dropout Layer\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         # Add a channel dimension\n",
    "#         x = x.unsqueeze(1)\n",
    "        \n",
    "#         # Apply Convolution Layer 1 and ReLU activation\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "#         # Apply Convolution Layer 2 and ReLU activation\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "#         # Flatten the output\n",
    "#         x = x.view(x.size(0), -1)\n",
    "        \n",
    "#         # Apply Fully Connected Layer 1 and ReLU activation\n",
    "#         x = F.relu(self.fc1(x))\n",
    "        \n",
    "#         # Apply Dropout\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         # Apply Fully Connected Layer 2 (Output Layer)\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# input_dim = train_dataset.features.shape[1]\n",
    "# model = QACNN(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QACNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(QACNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * (input_dim // 8), 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Ajouter une dimension channel\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = train_dataset.features.shape[1]\n",
    "model = QACNN(input_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.8069\n",
      "Epoch [2/20], Loss: 0.6887\n",
      "Epoch [3/20], Loss: 0.6697\n",
      "Epoch [4/20], Loss: 0.6396\n",
      "Epoch [5/20], Loss: 0.6048\n",
      "Epoch [6/20], Loss: 0.5801\n",
      "Epoch [7/20], Loss: 0.5405\n",
      "Epoch [8/20], Loss: 0.4943\n",
      "Epoch [9/20], Loss: 0.4597\n",
      "Epoch [10/20], Loss: 0.4344\n",
      "Epoch [11/20], Loss: 0.4127\n",
      "Epoch [12/20], Loss: 0.3920\n",
      "Epoch [13/20], Loss: 0.3625\n",
      "Epoch [14/20], Loss: 0.3564\n",
      "Epoch [15/20], Loss: 0.3441\n",
      "Epoch [16/20], Loss: 0.3356\n",
      "Epoch [17/20], Loss: 0.3427\n",
      "Epoch [18/20], Loss: 0.3288\n",
      "Epoch [19/20], Loss: 0.3134\n",
      "Epoch [20/20], Loss: 0.3155\n"
     ]
    }
   ],
   "source": [
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraîner le modèle\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation sur les données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.90      0.71       648\n",
      "           1       0.79      0.38      0.52       648\n",
      "\n",
      "    accuracy                           0.64      1296\n",
      "   macro avg       0.69      0.64      0.62      1296\n",
      "weighted avg       0.69      0.64      0.62      1296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle sur les données de validation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "validation_probabilities = np.array(all_probabilities)\n",
    "validation_labels = np.array(all_labels)\n",
    "\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(validation_labels, all_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "MAP: 0.40922568669006865\n",
      "MRR: 0.38425925925925924\n",
      "S@1: 0.3296296296296296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculer les métriques de validation\n",
    "map_score, mrr_score, success_at_1_score = utils.compute_metrics(balanced_validation_df, all_predictions, validation_probabilities)\n",
    "print(f\"\\nValidation Results:\\nMAP: {map_score}\\nMRR: {mrr_score}\\nS@1: {success_at_1_score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.88      0.70      1468\n",
      "           1       0.76      0.37      0.49      1468\n",
      "\n",
      "    accuracy                           0.62      2936\n",
      "   macro avg       0.67      0.62      0.60      2936\n",
      "weighted avg       0.67      0.62      0.60      2936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle sur les données de test\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "test_probabilities = np.array(all_probabilities)\n",
    "test_labels = np.array(all_labels)\n",
    "\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(test_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "MAP: 0.37046201472272033\n",
      "MRR: 0.34556542406805113\n",
      "S@1: 0.29071803852889666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculer les métriques de test\n",
    "map_score, mrr_score, success_at_1_score = utils.compute_metrics(balanced_test_df, all_predictions, test_probabilities)\n",
    "print(f\"\\nTest Results:\\nMAP: {map_score}\\nMRR: {mrr_score}\\nS@1: {success_at_1_score}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
